{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import Input, Dense, MultiHeadAttention, Flatten, Dropout, Reshape, LayerNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Embeddings Shape: (None, 1, 16)\n",
      "Normalized Attention Embeddings Shape: (None, 1, 16)\n",
      "Flattened Attention Embeddings Shape: (None, 16)\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 1024)]       0           []                               \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 256)          262400      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 256)          65792       ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 256)          65792       ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 128)          32896       ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " dense_4 (Dense)                (None, 64)           8256        ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " dense_5 (Dense)                (None, 32)           2080        ['dense_4[0][0]']                \n",
      "                                                                                                  \n",
      " dense_6 (Dense)                (None, 16)           528         ['dense_5[0][0]']                \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 1, 16)        0           ['dense_6[0][0]']                \n",
      "                                                                                                  \n",
      " multi_head_attention (MultiHea  (None, 1, 16)       12880       ['reshape[0][0]',                \n",
      " dAttention)                                                      'reshape[0][0]']                \n",
      "                                                                                                  \n",
      " layer_normalization (LayerNorm  (None, 1, 16)       32          ['multi_head_attention[0][0]']   \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1, 16)        0           ['layer_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 16)           0           ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dense_7 (Dense)                (None, 3)            51          ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 450,707\n",
      "Trainable params: 450,707\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_attention_transformer(input_shape):\n",
    "    # Create the Input Layer\n",
    "    input_layer = Input(shape=input_shape)\n",
    "\n",
    "    \n",
    "    dense_layer_one = Dense(256, activation='relu')(input_layer)\n",
    "    dense_layer_two = Dense(256, activation='relu')(dense_layer_one)\n",
    "    dense_layer_three = Dense(256, activation='relu')(dense_layer_two)\n",
    "    dense_layer_four = Dense(128, activation='relu')(dense_layer_three)\n",
    "\n",
    "    \n",
    "    dense_layer_five = Dense(64, activation='relu')(dense_layer_four)\n",
    "\n",
    "    dense_layer_six = Dense(32, activation='relu')(dense_layer_five)\n",
    "    \n",
    "    last_dense_layer = Dense(16, activation='relu')(dense_layer_six)   \n",
    "    \n",
    "    reshaped_layer = Reshape((1, 16))(last_dense_layer)\n",
    "\n",
    "    \n",
    "    attention = MultiHeadAttention(num_heads=3, key_dim=64)(reshaped_layer, reshaped_layer)\n",
    "    print(\"Attention Embeddings Shape:\", attention.shape)\n",
    "\n",
    "    \n",
    "    normalized_attention = LayerNormalization(epsilon=1e-6)(attention)\n",
    "    print(\"Normalized Attention Embeddings Shape:\", normalized_attention.shape)\n",
    "    dropout_attention = Dropout(0.1)(normalized_attention)\n",
    "\n",
    "    \n",
    "    flattened_attention = Flatten()(dropout_attention)\n",
    "    print(\"Flattened Attention Embeddings Shape:\", flattened_attention.shape)\n",
    "\n",
    "    \n",
    "    output_layer = Dense(7, activation='softmax')(flattened_attention)\n",
    "\n",
    "    \n",
    "    attention_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "    return attention_model\n",
    "\n",
    "# Define input shape\n",
    "attention_input_shape = (114,)  # Example input shape\n",
    "\n",
    "# Create the model\n",
    "attention_transformer_ecg = create_attention_transformer(attention_input_shape)\n",
    "\n",
    "# Compile the model with a decreased learning rate\n",
    "attention_transformer_ecg.compile(optimizer=tf.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy',tf.keras.metrics.Precision(name='precision'), tf.keras.metrics.Recall(name='recall')])\n",
    "\n",
    "# Print the model summary\n",
    "attention_transformer_ecg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ab_columns: [[48.84389  46.533704 25.924618 ...  2.388181  4.271034  4.093793]\n",
      " [34.108015 22.838567 20.646824 ...  2.507125  1.333279  7.415794]\n",
      " [31.084064 28.212342 30.467865 ...  6.313069  2.739807  7.6445  ]\n",
      " ...\n",
      " [20.05537  11.734445 15.719485 ...  1.180694  1.100077  0.741887]\n",
      " [26.43057  20.721589 25.486586 ...  0.976765  1.362347  1.168174]\n",
      " [14.64494  14.570681 13.731359 ...  0.442399  0.300771  0.411511]]\n",
      "coh_columns: [[85.05668  84.314205 88.042424 ... 30.893891 74.038603 51.237679]\n",
      " [84.994328 57.571481 75.298051 ... 40.297206 55.547526 63.630547]\n",
      " [43.406463 33.374232 37.783015 ... 53.49483  66.581021 80.202968]\n",
      " ...\n",
      " [59.618728 56.295958 73.067333 ... 62.032961 79.282698 80.363086]\n",
      " [73.70224  56.132581 67.605944 ... 27.534399 40.861627 49.097135]\n",
      " [82.495367 53.115312 71.716848 ... 43.366516 59.321302 51.526134]]\n",
      "other_columns: [[1 'F' 31.55 ... 103.0 'Mood disorder' 'Depressive disorder']\n",
      " [2 'M' 25.0 ... 115.0 'Healthy control' 'Healthy control']\n",
      " [3 'M' 26.2 ... 83.0 'Schizophrenia' 'Schizophrenia']\n",
      " ...\n",
      " [943 'M' 20.08 ... 93.0 'Mood disorder' 'Depressive disorder']\n",
      " [944 'F' 33.5 ... 103.0 'Mood disorder' 'Depressive disorder']\n",
      " [945 'F' 40.28 ... 102.0 'Trauma and stress related disorder'\n",
      "  'Acute stress disorder']]\n"
     ]
    }
   ],
   "source": [
    "# Load the .npy files\n",
    "ab_columns = np.load(\"ab_columns.npy\", allow_pickle=True)\n",
    "coh_columns = np.load(\"coh_columns.npy\", allow_pickle=True)\n",
    "other_columns = np.load(\"other_columns.npy\", allow_pickle=True)\n",
    "\n",
    "# Print the loaded data\n",
    "print(\"ab_columns:\", ab_columns)\n",
    "print(\"coh_columns:\", coh_columns)\n",
    "print(\"other_columns:\", other_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (681, 114)\n",
      "X_val shape: (171, 114)\n",
      "y_train shape: (681,)\n",
      "y_val shape: (171,)\n"
     ]
    }
   ],
   "source": [
    "labels = other_columns[:, 6]\n",
    "X_train, X_val, y_train, y_val = train_test_split(ab_columns, labels, test_size=0.2, random_state=42, stratify=labels)\n",
    "\n",
    "# Print shapes to verify\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
